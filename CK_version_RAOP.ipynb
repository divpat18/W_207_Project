{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "",
  "signature": "sha256:9b6c1e0cb0155ada610784039f554686d04eaef67acfeba790c79fc11ab3a286"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json as js\n",
      "import random\n",
      "from sklearn import metrics\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import *\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I know you had this as a function call, but that didn't seem to work well for me in the ipynb - it was fine as a script, but not as a notebook. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Reads the json file as a String\n",
      "data2 = open(\"train.json\").read()\n",
      "#Converts JSON string to a List of Dictionaries\n",
      "jsondata2 = js.loads(data2)\n",
      "#Dictionary Storing the final values.\n",
      "json_training_data={}\n",
      "# Going through the JSON data and storing the the data with key as \"RequesterID:TimestampOfRequest\"\n",
      "for data_index in range(len(jsondata2)):\n",
      "        data = dict(jsondata2[data_index])\n",
      "        json_training_data[data.get(\"requester_username\")+\":\"+str(data.get(\"unix_timestamp_of_request_utc\"))]=data\n",
      "print \"Length JSON data\", len(jsondata2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Length JSON data 4040\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define categories for variables (numeric, text, and outcome)\n",
      "\n",
      "NOTE that the following variables are not currently imported and will require extra processing:\n",
      "\n",
      "1) requester_subreddits_at_request (returns an array)\n",
      "2) unix timestamp of request (date format)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numeric_variables = ['number_of_downvotes_of_request_at_retrieval',\n",
      "    'number_of_upvotes_of_request_at_retrieval',\n",
      "    'post_was_edited',\n",
      "    'request_number_of_comments_at_retrieval',\n",
      "    'requester_account_age_in_days_at_request',\n",
      "    'requester_account_age_in_days_at_request',\n",
      "    'requester_account_age_in_days_at_retrieval',\n",
      "    'requester_days_since_first_post_on_raop_at_request',\n",
      "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
      "    'requester_number_of_comments_at_request',\n",
      "    'requester_number_of_comments_at_retrieval',\n",
      "    'requester_number_of_comments_in_raop_at_request',\n",
      "    'requester_number_of_comments_in_raop_at_retrieval',\n",
      "    'requester_number_of_posts_at_request',\n",
      "    'requester_number_of_posts_at_retrieval',\n",
      "    'requester_number_of_posts_on_raop_at_request',\n",
      "    'requester_number_of_posts_on_raop_at_retrieval',\n",
      "    'requester_number_of_subreddits_at_request',\n",
      "    'requester_upvotes_minus_downvotes_at_request',\n",
      "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
      "    'requester_upvotes_plus_downvotes_at_request',\n",
      "    'requester_upvotes_plus_downvotes_at_retrieval'\n",
      "    'unix_timestamp_of_request_utc']\n",
      "    \n",
      "text_variables = ['giver_username_if_known',\n",
      "    'request_id',\n",
      "    'request_text',\n",
      "    'request_text_edit_aware',\n",
      "    'request_title',\n",
      "    'requester_user_flair',\n",
      "    'requester_username']\n",
      "\n",
      "numeric_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = numeric_variables)\n",
      "text_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = text_variables)\n",
      "outcome = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = ['requester_received_pizza'])\n",
      "\n",
      "print \"Number of numeric variables: \", len(numeric_elements.columns)\n",
      "print \"Number of text variables: \", len(text_elements.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of numeric variables:  22\n",
        "Number of text variables:  7\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loop to transform JSON into arrays."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(jsondata2)):\n",
      "    mykeys = jsondata2[i].keys()\n",
      "    myvals = jsondata2[i].values()\n",
      "    for key, val in zip(mykeys, myvals):\n",
      "        if key in numeric_variables:\n",
      "            idx = numeric_variables.index(key)\n",
      "            numeric_elements.iloc[i, idx] = val\n",
      "        if key in text_variables:\n",
      "            idx = text_variables.index(key)\n",
      "            text_elements.iloc[i, idx] = val\n",
      "        if key == 'requester_received_pizza':\n",
      "            outcome.iloc[i,0] = val\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Output shapes of numeric, text, and outcome arrays\n",
      "print \"Numeric array:\"\n",
      "print numeric_elements.shape\n",
      "print \n",
      "\n",
      "print \"Text array:\"\n",
      "print text_elements.shape\n",
      "print\n",
      "\n",
      "print \"Outcome array:\"\n",
      "print outcome.shape\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Numeric array:\n",
        "(4040, 22)\n",
        "\n",
        "Text array:\n",
        "(4040, 7)\n",
        "\n",
        "Outcome array:\n",
        "(4040, 1)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Splitting data into training, dev, and test sets (80/10/10)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "random.seed(500)\n",
      "data_size = len(jsondata2)\n",
      "print \"data_size\", data_size\n",
      "\n",
      "test_indices = random.sample(range(data_size), data_size / 5)\n",
      "train_indices = list(set(range(data_size)) - set(test_indices))\n",
      "dev_indices = random.sample(test_indices, len(test_indices) / 2)\n",
      "test_indices= list(set(test_indices) - set(dev_indices))\n",
      "\n",
      "print \"Number of training cases: \", len(train_indices)\n",
      "print \"Number of dev cases: \", len(dev_indices)\n",
      "print \"Number of test cases: \", len(test_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data_size 4040\n",
        "Number of training cases:  3232\n",
        "Number of dev cases:  404\n",
        "Number of test cases:  404\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_request_text = text_elements.ix[train_indices, \"request_text\"]\n",
      "dev_request_text = text_elements.ix[dev_indices, \"request_text\"]\n",
      "\n",
      "train_outcome = outcome.ix[train_indices,].astype(int).sum(axis = 1)\n",
      "dev_outcome = outcome.ix[dev_indices,].astype(int).sum(axis = 1)\n",
      "print \"training shape: \", train_outcome.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "training shape:  (3232,)\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create vectorizer\n",
      "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = \"english\")\n",
      "train_data_features = vectorizer.fit_transform(train_request_text)\n",
      "train_vocab = vectorizer.get_feature_names()\n",
      "\n",
      "vectorizer_dev = CountVectorizer(analyzer = \"word\", tokenizer= None, preprocessor = None, stop_words = \"english\", vocabulary = train_vocab)\n",
      "dev_data_features = vectorizer_dev.fit_transform(dev_request_text)\n",
      "#"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "log_regression = LogisticRegression(penalty = \"l2\", C = 1)\n",
      "log_regression.fit(train_data_features, train_outcome)\n",
      "dev_predicted_labels = log_regression.predict(dev_data_features)\n",
      "print \"Confusion matrix on dev data for Logistic Regression model no processing, using only request_text: \"\n",
      "print metrics.confusion_matrix(dev_outcome, dev_predicted_labels, labels = [0,1])\n",
      "print\n",
      "\n",
      "print \"Classification report: \"\n",
      "print metrics.classification_report(dev_outcome, dev_predicted_labels, labels = [0, 1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Confusion matrix on dev data for Logistic Regression model no processing, using only request_text: \n",
        "[[262  28]\n",
        " [ 82  32]]\n",
        "\n",
        "Classification report: \n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.76      0.90      0.83       290\n",
        "          1       0.53      0.28      0.37       114\n",
        "\n",
        "avg / total       0.70      0.73      0.70       404\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}