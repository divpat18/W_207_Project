{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divyang Prateek, Brennan Borlaug, Cory Kind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing and structuring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing relevant libraries for storing and analyzing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in JSON file of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reads the json file as a String\n",
    "data2 = open(\"train.json\").read()\n",
    "#Converts JSON string to a List of Dictionaries\n",
    "jsondata2 = js.loads(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAOP data contains a variety of predictors of different formats. This step puts variables into separate categories for text and numeric, and creates an array for the outcome we are trying to predict (\"requester_received_pizza\"). We decided it was easier to work with text and numeric variables separately at this stage.\n",
    "\n",
    "\n",
    "NOTE that the following variables are not currently imported because they require extra processing. They will be addressed at a later point, but are not required for the baseline.\n",
    "\n",
    "1) requester_subreddits_at_request (returns an array)\n",
    "\n",
    "2) unix timestamp of request (date format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric variables:  23\n",
      "Number of text variables:  7\n"
     ]
    }
   ],
   "source": [
    "#numeric variables\n",
    "numeric_variables = ['number_of_downvotes_of_request_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'post_was_edited',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_account_age_in_days_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_comments_at_retrieval',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_retrieval',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_posts_at_retrieval',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_retrieval',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "    'unix_timestamp_of_request_utc']\n",
    "\n",
    "#requester variables (from time of request)\n",
    "requester_variables = ['requester_account_age_in_days_at_request',\n",
    "                      'requester_days_since_first_post_on_raop_at_request',\n",
    "                      'requester_number_of_comments_at_request',\n",
    "                      'requester_number_of_comments_in_raop_at_request',\n",
    "                      'requester_number_of_posts_at_request',\n",
    "                      'requester_number_of_posts_on_raop_at_request',\n",
    "                      'requester_number_of_subreddits_at_request',\n",
    "                      'requester_upvotes_minus_downvotes_at_request',\n",
    "                      'requester_upvotes_plus_downvotes_at_request']\n",
    "\n",
    "\n",
    "#text variables\n",
    "text_variables = ['giver_username_if_known',\n",
    "    'request_id',\n",
    "    'request_text',\n",
    "    'request_text_edit_aware',\n",
    "    'request_title',\n",
    "    'requester_user_flair',\n",
    "    'requester_username']\n",
    "\n",
    "#Creating empty data frames to store the training data\n",
    "numeric_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = numeric_variables)\n",
    "text_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = text_variables)\n",
    "requester_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = requester_variables)\n",
    "outcome = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = ['requester_received_pizza'])\n",
    "\n",
    "#Print the number of text and numeric predictors currently included\n",
    "print \"Number of numeric variables: \", len(numeric_elements.columns)\n",
    "print \"Number of text variables: \", len(text_elements.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to fill these arrays from the JSON data. Although the loop approach is less efficient at large scale, we went this direction because the number of keys varies between cases in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(jsondata2)):\n",
    "    mykeys = jsondata2[i].keys()\n",
    "    myvals = jsondata2[i].values()\n",
    "    for key, val in zip(mykeys, myvals):\n",
    "        if key in numeric_variables:\n",
    "            idx = numeric_variables.index(key)\n",
    "            numeric_elements.iloc[i, idx] = val\n",
    "        if key in requester_variables:\n",
    "            idx = requester_variables.index(key)\n",
    "            requester_elements.iloc[i, idx] = val\n",
    "        if key in text_variables:\n",
    "            idx = text_variables.index(key)\n",
    "            text_elements.iloc[i, idx] = val\n",
    "        if key == 'requester_received_pizza':\n",
    "            outcome.iloc[i,0] = val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick check on the size of these arrays - the number of columns should match the number of text and numeric predictors determined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric array:\n",
      "(4040, 23)\n",
      "\n",
      "Requester array:\n",
      "(4040, 9)\n",
      "\n",
      "Text array:\n",
      "(4040, 7)\n",
      "\n",
      "Outcome array:\n",
      "(4040, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Output shapes of numeric, text, and outcome arrays\n",
    "print \"Numeric array:\"\n",
    "print numeric_elements.shape\n",
    "print \n",
    "\n",
    "print \"Requester array:\"\n",
    "print requester_elements.shape\n",
    "print\n",
    "\n",
    "print \"Text array:\"\n",
    "print text_elements.shape\n",
    "print\n",
    "\n",
    "print \"Outcome array:\"\n",
    "print outcome.shape\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split out a dev set from the provided training data (80/20). There is no need to separate out a test set, since that is provided by Kaggle in a separate JSON file. To compare our results to other competitors in the Kaggle competition, we will need to use that test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training cases:  3232\n",
      "Number of dev cases:  808\n"
     ]
    }
   ],
   "source": [
    "random.seed(500)\n",
    "data_size = len(jsondata2)\n",
    "dev_indices = random.sample(range(data_size), data_size / 5)\n",
    "train_indices = list(set(range(data_size)) - set(dev_indices))\n",
    "\n",
    "#Define training & dev sets\n",
    "train_requester_feats = requester_elements.ix[train_indices,]\n",
    "train_outcomes = outcome.ix[train_indices,].astype(int).sum(axis = 1)\n",
    "dev_requester_feats = requester_elements.ix[dev_indices,]\n",
    "dev_outcomes = outcome.ix[dev_indices,].astype(int).sum(axis = 1)\n",
    "\n",
    "print \"Number of training cases: \", len(train_indices)\n",
    "print \"Number of dev cases: \", len(dev_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Creating features for the baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the set-up is over, we can start using the text of the request to extract more interesting predictors. As a baseline, we're going to build a logistic regression model based on the word counts from the request text alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pull out the request text and outcomes for training and dev sets\n",
    "train_request_text = text_elements.ix[train_indices, \"request_text\"]\n",
    "dev_request_text = text_elements.ix[dev_indices, \"request_text\"]\n",
    "\n",
    "train_outcome = outcome.ix[train_indices,].astype(int).sum(axis = 1)\n",
    "dev_outcome = outcome.ix[dev_indices,].astype(int).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create CountVectorizer object with no preprocessing, but include basic English stop words\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = \"english\")\n",
    "train_data_features = vectorizer.fit_transform(train_request_text)\n",
    "train_vocab = vectorizer.get_feature_names()\n",
    "\n",
    "#Use train_vocab to extract the same features from the dev set\n",
    "vectorizer_dev = CountVectorizer(analyzer = \"word\", tokenizer= None, preprocessor = None, stop_words = \"english\", vocabulary = train_vocab)\n",
    "dev_data_features = vectorizer_dev.fit_transform(dev_request_text)\n",
    "\n",
    "print \"The length of the vocabulary using this basic model is: \", str(len(train_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fitting a logistic regression model and printing confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fit L2 Logistic Regression model\n",
    "log_regression = LogisticRegression(penalty = \"l2\", C = 1)\n",
    "log_regression.fit(train_data_features, train_outcome)\n",
    "dev_predicted_labels = log_regression.predict(dev_data_features)\n",
    "\n",
    "#Print confusion matrix and classification report\n",
    "print \"Confusion matrix on dev data for Logistic Regression model no processing, using only request_text: \"\n",
    "print metrics.confusion_matrix(dev_outcome, dev_predicted_labels, labels = [0,1])\n",
    "print\n",
    "\n",
    "print \"Classification report: \"\n",
    "print metrics.classification_report(dev_outcome, dev_predicted_labels, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are pretty happy with this as a first attempt. There is a lot of room for growth, but even with our very basic model we're seeing decent initial results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Directions for future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick check of our initial model, we pulled out the 20 unigrams with the largest weights. This can also help us think through what patterns to look for in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting 20 largest weights from the logistic regression model and printing\n",
    "weights = log_regression.coef_\n",
    "top_weights = np.argpartition(weights[0,], -19)[-20:]\n",
    "\n",
    "#Printing out features\n",
    "print \"Unigram Features with Largest Weights\"\n",
    "for j in top_weights:\n",
    "    print str(train_vocab[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words seem directionally correct based on our early reviews of the request_text variable and the kind of requests people make. \"Rice\" is often presented as an alternative to pizza (i.e., \"I've been eating rice for a week - pizza would be a nice change\"). A second note is that \"op\" is part of the Reddit lexicon. One hypothesis is that requesters who come across as insiders are more likely to get pizza. To test for that, we can include measures like # of subreddits and length of Reddit history. A couple of other ideas we have include:\n",
    "\n",
    "- Time (seasonality, day of week, are people more likely to give at certain times of the month)\n",
    "- Text (extracting predictors from request titles, include bigrams/triagrams, # of spelling errors, potentially sentiment analysis)\n",
    "- Reddit behaviors (number of sub-reddits, length of time on Reddit, upvote/downvote differential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin to develop a predictive model, we must establish a baseline to give ourselves a sense of what we are trying to achieve. In our application, the following models would serve as an effective baseline: \n",
    "    1. A model that always predicts the most frequent label (in this case, no pizza).\n",
    "    2. A model that predicts outcomes with the probability of the mean response (e.g. 26.6% of requesters receive a pizza, therefore the model will predict positive outcomes 24.6% of the time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 0\n",
    "r = 0\n",
    "outcomes = []\n",
    "for request in jsondata2:\n",
    "    if request['requester_received_pizza'] == True:\n",
    "        y+=1\n",
    "        r+=1\n",
    "        outcomes.append(1)\n",
    "    else:\n",
    "        r+=1\n",
    "        outcomes.append(0)\n",
    "avg = float(y)/float(r)\n",
    "\n",
    "#Baseline 1\n",
    "base1 = [0]*len(jsondata2)\n",
    "c = 0\n",
    "n = 0\n",
    "for i, j in zip(base1, outcomes):\n",
    "    if i == j:\n",
    "        c+=1\n",
    "        n+=1\n",
    "    else:\n",
    "        n+=1\n",
    "print 'Baseline 1 Accuracy:', round(float(c)/float(n),4)*100, '%'\n",
    "\n",
    "#Baseline 2\n",
    "base2 = np.random.binomial(1, avg, size=len(jsondata2))\n",
    "c = 0\n",
    "n = 0\n",
    "for i, j in zip(base2, outcomes):\n",
    "    if i == j:\n",
    "        c+=1\n",
    "        n+=1\n",
    "    else:\n",
    "        n+=1        \n",
    "print 'Baseline 2 Accuracy:', round(float(c)/float(n),4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple logistic regression model\n",
    "clf = LogisticRegression(penalty = \"l2\")\n",
    "clf.fit(train_requester_feats, train_outcomes)\n",
    "preds = clf.predict(dev_requester_feats)\n",
    "probs = clf.predict_proba(dev_requester_feats)\n",
    "\n",
    "pred_probs=[]\n",
    "for prob in probs:\n",
    "    pred_probs.append(max(prob[0], prob[1]))\n",
    "\n",
    "#print pd.DataFrame(zip(preds,pred_probs))\n",
    "\n",
    "print 'Simple Regression Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, preds),4)*100, '%','\\n'\n",
    "print 'Confusion Matrix:'\n",
    "print metrics.confusion_matrix(dev_outcomes, preds), '\\n'\n",
    "print 'Classification Report:'\n",
    "print metrics.classification_report(dev_outcomes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Examine the coefficients\n",
    "print pd.DataFrame(zip(requester_variables, np.transpose(clf.coef_)), \n",
    "                   columns=['features', 'coefs']).sort_values('coefs', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Tune hyperparameter C\n",
    "params = np.arange(0.05, 5, 0.05)\n",
    "acc = []\n",
    "\n",
    "for c in params:\n",
    "    clf = LogisticRegression(penalty = \"l2\", C=c)\n",
    "    clf.fit(train_requester_feats, train_outcomes)\n",
    "    preds = clf.predict(dev_requester_feats)\n",
    "    acc.append(metrics.accuracy_score(dev_outcomes, preds))\n",
    "\n",
    "optimal_c = params[acc.index(max(acc))]\n",
    "print 'Logistic Regression:'\n",
    "print 'optimal c: ', optimal_c, '; accuracy: ', round(max(acc), 4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that wasn't very enlightening. I'm pretty sure C defaults to 1.0...\n",
    "\n",
    "Now I'll see if it helps to normalize the features (so they are on the same scale - Z-scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create new dataframe to store scaled training features\n",
    "norm_train_feats = pd.DataFrame()\n",
    "\n",
    "norm_train_feats['requester_account_age_in_days_at_request'] = preprocessing.scale(train_requester_feats['requester_account_age_in_days_at_request'])\n",
    "norm_train_feats['requester_days_since_first_post_on_raop_at_request'] = preprocessing.scale(train_requester_feats['requester_days_since_first_post_on_raop_at_request'])\n",
    "norm_train_feats['requester_number_of_comments_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_comments_at_request'])\n",
    "norm_train_feats['requester_number_of_comments_in_raop_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_comments_in_raop_at_request'])                      \n",
    "norm_train_feats['requester_number_of_posts_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_posts_at_request'])    \n",
    "norm_train_feats['requester_number_of_posts_on_raop_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_posts_on_raop_at_request'])                      \n",
    "norm_train_feats['requester_number_of_subreddits_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_subreddits_at_request'])    \n",
    "norm_train_feats['requester_upvotes_minus_downvotes_at_request'] = preprocessing.scale(train_requester_feats['requester_upvotes_minus_downvotes_at_request'])\n",
    "norm_train_feats['requester_upvotes_plus_downvotes_at_request'] = preprocessing.scale(train_requester_feats['requester_upvotes_plus_downvotes_at_request'])                     \n",
    "\n",
    "#Create dataframe for scaled dev features\n",
    "norm_dev_feats = pd.DataFrame()\n",
    "\n",
    "norm_dev_feats['requester_account_age_in_days_at_request'] = preprocessing.scale(dev_requester_feats['requester_account_age_in_days_at_request'])\n",
    "norm_dev_feats['requester_days_since_first_post_on_raop_at_request'] = preprocessing.scale(dev_requester_feats['requester_days_since_first_post_on_raop_at_request'])\n",
    "norm_dev_feats['requester_number_of_comments_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_comments_at_request'])\n",
    "norm_dev_feats['requester_number_of_comments_in_raop_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_comments_in_raop_at_request'])                      \n",
    "norm_dev_feats['requester_number_of_posts_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_posts_at_request'])    \n",
    "norm_dev_feats['requester_number_of_posts_on_raop_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_posts_on_raop_at_request'])                      \n",
    "norm_dev_feats['requester_number_of_subreddits_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_subreddits_at_request'])    \n",
    "norm_dev_feats['requester_upvotes_minus_downvotes_at_request'] = preprocessing.scale(dev_requester_feats['requester_upvotes_minus_downvotes_at_request'])\n",
    "norm_dev_feats['requester_upvotes_plus_downvotes_at_request'] = preprocessing.scale(dev_requester_feats['requester_upvotes_plus_downvotes_at_request'])                     \n",
    "\n",
    "#Create logistic regression model with normalized features\n",
    "norm_clf = LogisticRegression(penalty = \"l2\")\n",
    "norm_clf.fit(norm_train_feats, train_outcomes)\n",
    "norm_preds = norm_clf.predict(norm_dev_feats)\n",
    "\n",
    "print 'Normalized Regression Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, norm_preds),4)*100, '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the features did not yield an improvement to the model but it allows me to better visualize which features are having the greatest predictive power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pd.DataFrame(zip(requester_variables, np.transpose(norm_clf.coef_)), \n",
    "                   columns=['features', 'coefs']).sort_values('coefs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', n_neighbors=11) #tested 1,3,5,7,9,11,13,& 15 neighbors to select best parameter\n",
    "knn.fit(train_requester_feats, train_outcomes)\n",
    "knn_preds = knn.predict(dev_requester_feats)\n",
    "\n",
    "norm_knn = KNeighborsClassifier()\n",
    "norm_knn.fit(norm_train_feats, train_outcomes)\n",
    "norm_knn_preds = norm_knn.predict(norm_dev_feats)\n",
    "\n",
    "print 'Nearest Neighbors Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, knn_preds),4)*100, '%'\n",
    "print 'Nearest Neighbors (Norm. Feats) Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, norm_knn_preds),4)*100, '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Centroid\n",
    "\n",
    "The Nearest Centroid classifier is a simple algorithm that represents each class by the centroid of its members. A new set of features is classified based on its distance from the centroids of the features in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nc = NearestCentroid()\n",
    "nc.fit(train_requester_feats, train_outcomes)\n",
    "nc_preds = nc.predict(dev_requester_feats)\n",
    "\n",
    "norm_nc = NearestCentroid()\n",
    "norm_nc.fit(norm_train_feats, train_outcomes)\n",
    "norm_nc_preds = norm_nc.predict(norm_dev_feats)\n",
    "\n",
    "print 'Nearest Centroid Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, nc_preds),4)*100, '%'\n",
    "print 'Nearest Centroid (Norm. Feats) Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, norm_nc_preds),4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators=[]\n",
    "accuracies=[]\n",
    "\n",
    "for i in range(1,30):\n",
    "    rf = RandomForestClassifier(n_estimators=i, random_state=99)\n",
    "    rf.fit(train_requester_feats, train_outcomes)\n",
    "    rf_preds=rf.predict(dev_requester_feats)\n",
    "    acc = metrics.accuracy_score(dev_outcomes, rf_preds)\n",
    "    estimators.append(i)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "max_acc = max(accuracies)\n",
    "est = estimators[accuracies.index(max_acc)]\n",
    "print 'Random Forests Model Accuracy (', est, 'estimators ):', round(max_acc,4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learner\n",
    "Lastly, I will test a model that takes the most frequent prediction from the logistic regression, nearest neighbors (n=11), & random forest (n_estimators=26) models outlined above as its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "reg = LogisticRegression(penalty=\"l2\", C=1.0)\n",
    "reg.fit(train_requester_feats, train_outcomes)\n",
    "reg_preds = clf.predict(dev_requester_feats)\n",
    "\n",
    "#Nearest Neighbors\n",
    "knn = KNeighborsClassifier(algorithm='auto', n_neighbors=11)\n",
    "knn.fit(train_requester_feats, train_outcomes)\n",
    "knn_preds = knn.predict(dev_requester_feats)\n",
    "\n",
    "#Random Forests\n",
    "rf = RandomForestClassifier(n_estimators=26, random_state=99)\n",
    "rf.fit(train_requester_feats, train_outcomes)\n",
    "rf_preds=rf.predict(dev_requester_feats)\n",
    "\n",
    "ensemble_preds=[]\n",
    "\n",
    "for i,j,k in zip(reg_preds, knn_preds, rf_preds):\n",
    "    pred=[]\n",
    "    pred.append(i), pred.append(j), pred.append(k)\n",
    "    ensemble_preds.append(max(set(pred)))\n",
    "    \n",
    "print 'Ensemble Learner Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, ensemble_preds),4)*100, '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, here are the models, ranked in terms of accuracy, for requester features: \n",
    "  \n",
    "1) Logistic regression (non-normalized feats) - 75.12%  \n",
    "2) Random forests - 73.64%  \n",
    "3) Nearest neighbors - 73.02%  \n",
    "4) Ensemble learner - 72.77%  \n",
    "5) Nearest centroid - 67.7%  \n",
    "  \n",
    "All 5 models were better than guessing based on the outcome distribution (63.37%) but were not better than guessing the most common outcome (75.4%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extracting the numerical data and converting to datetime.\n",
    "train_request_time = numeric_elements.ix[train_indices,\"unix_timestamp_of_request_utc\"].astype(long)\n",
    "train_request_dateTime = [datetime.datetime.fromtimestamp(time) for time in train_request_time]\n",
    "dev_request_time = numeric_elements.ix[dev_indices,\"unix_timestamp_of_request_utc\"].astype(long)\n",
    "dev_request_dateTime = [datetime.datetime.fromtimestamp(time) for time in dev_request_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score : 0.706683168317\n",
      "Logistic Regression Score : 0.738861386139\n"
     ]
    }
   ],
   "source": [
    "train_month = np.asarray([time.month for time in train_request_dateTime]).reshape((len(train_request_time),1))\n",
    "train_month_label = np.asarray(train_outcomes)\n",
    "\n",
    "dev_month = np.asarray([time.month for time in dev_request_dateTime]).reshape((len(dev_request_time),1))\n",
    "dev_month_label = np.asarray(dev_outcomes)\n",
    "\n",
    "knn_clf  = KNeighborsClassifier()\n",
    "knn_clf = knn_clf.fit(train_month,train_month_label)\n",
    "print 'KNN Score :',knn_clf.score(dev_month,dev_month_label)\n",
    "\n",
    "lr_clf = LogisticRegression(C=1)\n",
    "lr_clf = lr_clf.fit(train_month,train_month_label)\n",
    "print 'Logistic Regression Score :',lr_clf.score(dev_month,dev_month_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score : 0.738861386139\n",
      "Logistic Regression Score : 0.738861386139\n"
     ]
    }
   ],
   "source": [
    "train_holiday_season = np.asarray([time.month >= 10 for time in train_request_dateTime]).reshape((len(train_request_time),1))\n",
    "train_holiday_label = np.asarray(train_outcomes)\n",
    "\n",
    "dev_holiday_season = np.asarray([time.month >= 10 for time in dev_request_dateTime]).reshape((len(dev_request_time),1))\n",
    "dev_holiday_label = np.asarray(dev_outcomes)\n",
    "\n",
    "knn_clf  = KNeighborsClassifier()\n",
    "knn_clf = knn_clf.fit(train_holiday_season,train_holiday_label)\n",
    "print 'KNN Score :',knn_clf.score(dev_holiday_season,dev_holiday_label)\n",
    "\n",
    "lr_clf = LogisticRegression(C=1)\n",
    "lr_clf = lr_clf.fit(train_holiday_season,train_holiday_label)\n",
    "print 'Logistic Regression Score :',lr_clf.score(dev_holiday_season,dev_holiday_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score : 0.738861386139\n",
      "Logistic Regression Score : 0.738861386139\n",
      "(3232, 1)\n"
     ]
    }
   ],
   "source": [
    "train_payday_effect = np.asarray([(time.day > 26 or time.day<2) for time in train_request_dateTime]).reshape((len(train_request_time),1))\n",
    "train_payday_label = np.asarray(train_outcomes)\n",
    "\n",
    "dev_payday_effect = np.asarray([(time.day > 26 or time.day<2) for time in dev_request_dateTime]).reshape((len(dev_request_time),1))\n",
    "dev_payday_label = np.asarray(dev_outcomes)\n",
    "\n",
    "knn_clf_pe  = KNeighborsClassifier()\n",
    "knn_clf_pe = knn_clf_pe.fit(train_payday_effect,train_payday_label)\n",
    "print 'KNN Score :',knn_clf.score(dev_payday_effect,dev_payday_label)\n",
    "\n",
    "lr_clf = LogisticRegression(C=1)\n",
    "lr_clf = lr_clf.fit(train_payday_effect,train_payday_label)\n",
    "print 'Logistic Regression Score :',lr_clf.score(dev_payday_effect,dev_payday_label)\n",
    "\n",
    "print train_payday_effect.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_features(train_data,train_labels, dev_data,dev_labels):\n",
    "    #Nearest Neighbour Classifier\\\n",
    "    knn_scores=[]\n",
    "    knn_estimators=[]\n",
    "    for k in range(1,16):\n",
    "        knn = KNeighborsClassifier(algorithm='auto', n_neighbors=k) #tested 1,3,5,7,9,11,13,& 15 neighbors to select best parameter\n",
    "        knn.fit(train_data, train_labels)\n",
    "        knn_preds = knn.predict(dev_data)\n",
    "        knn_scores.append(round(metrics.accuracy_score(dev_outcomes, knn_preds),4)*100)\n",
    "        knn_estimators.append(k)\n",
    "    \n",
    "    print 'Nearest Neighbors Model Accuracy:', max(knn_scores), '%', ' with n_neighbours:',knn_estimators[knn_scores.index(max(knn_scores))]\n",
    "    \n",
    "    #Nearest Centroid Classifier\n",
    "    nc = NearestCentroid()\n",
    "    nc.fit(train_data, train_labels)\n",
    "    nc_preds = nc.predict(dev_data)\n",
    "    \n",
    "    print 'Nearest Centroid Model Accuracy:', round(metrics.accuracy_score(dev_labels, nc_preds),4)*100, '%'\n",
    "    \n",
    "    #Logistic Regression\n",
    "    reg = LogisticRegression(penalty=\"l2\", C=1.0)\n",
    "    reg.fit(train_data, train_labels)\n",
    "    reg_preds = reg.predict(dev_data)\n",
    "    \n",
    "    print 'Logistic Regression Model Accuracy:', round(metrics.accuracy_score(dev_labels, reg_preds),4)*100, '%'\n",
    "\n",
    "    estimators=[]\n",
    "    accuracies=[]\n",
    "\n",
    "    for i in range(1,30):\n",
    "        rf = RandomForestClassifier(n_estimators=i, random_state=99)\n",
    "        rf.fit(train_requester_feats, train_outcomes)\n",
    "        rf_preds=rf.predict(dev_requester_feats)\n",
    "        acc = metrics.accuracy_score(dev_outcomes, rf_preds)\n",
    "        estimators.append(i)\n",
    "        accuracies.append(acc)\n",
    "\n",
    "    max_acc = max(accuracies)\n",
    "    est = estimators[accuracies.index(max_acc)]\n",
    "    print 'Random Forests Model Accuracy (', est, 'estimators ):', round(max_acc,4)*100, '%'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232, 10)\n",
      "Nearest Neighbors Model Accuracy: 73.51 %  with n_neighbours: 10\n",
      "Nearest Centroid Model Accuracy: 67.7 %\n",
      "Logistic Regression Model Accuracy: 74.75 %\n",
      "Random Forests Model Accuracy ( 28 estimators ): 72.9 %\n",
      "Nearest Neighbors Model Accuracy: 73.51 %  with n_neighbours: 10\n",
      "Nearest Centroid Model Accuracy: 67.7 %\n",
      "Logistic Regression Model Accuracy: 74.75 %\n",
      "Random Forests Model Accuracy ( 28 estimators ): 72.9 %\n"
     ]
    }
   ],
   "source": [
    "print train_requester_feats.shape\n",
    "evaluate_features(train_requester_feats,train_outcomes,dev_requester_feats,dev_outcomes)\n",
    "train_requester_feats['unix_timestamp_of_request_utc'] = train_month.astype('float64')\n",
    "dev_requester_feats['unix_timestamp_of_request_utc'] = dev_month.astype('float64')\n",
    "evaluate_features(train_requester_feats,train_outcomes,dev_requester_feats,dev_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
