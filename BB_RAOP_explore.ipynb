{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brennan Borlaug, Divyang Prateek, and Cory Kind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing and structuring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing relevant libraries for storing and analyzing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in JSON file of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reads the json file as a String\n",
    "dl_dir = '/home/bborlaug/Downloads'\n",
    "os.chdir(dl_dir)\n",
    "data2 = open(\"train.json\").read()\n",
    "#Converts JSON string to a List of Dictionaries\n",
    "jsondata2 = js.loads(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAOP data contains a variety of predictors of different formats. This step puts variables into separate categories for text and numeric, and creates an array for the outcome we are trying to predict (\"requester_received_pizza\"). We decided it was easier to work with text and numeric variables separately at this stage.\n",
    "\n",
    "\n",
    "NOTE that the following variables are not currently imported because they require extra processing. They will be addressed at a later point, but are not required for the baseline.\n",
    "\n",
    "1) requester_subreddits_at_request (returns an array)\n",
    "\n",
    "2) unix timestamp of request (date format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric variables:  22\n",
      "Number of requester variables:  9\n",
      "Number of text variables:  7\n"
     ]
    }
   ],
   "source": [
    "#numeric variables\n",
    "numeric_variables = ['number_of_downvotes_of_request_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'post_was_edited',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_account_age_in_days_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_comments_at_retrieval',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_retrieval',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_posts_at_retrieval',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_retrieval',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "    'unix_timestamp_of_request_utc']\n",
    "\n",
    "#requester variables (from time of request)\n",
    "requester_variables = ['requester_account_age_in_days_at_request',\n",
    "                      'requester_days_since_first_post_on_raop_at_request',\n",
    "                      'requester_number_of_comments_at_request',\n",
    "                      'requester_number_of_comments_in_raop_at_request',\n",
    "                      'requester_number_of_posts_at_request',\n",
    "                      'requester_number_of_posts_on_raop_at_request',\n",
    "                      'requester_number_of_subreddits_at_request',\n",
    "                      'requester_upvotes_minus_downvotes_at_request',\n",
    "                      'requester_upvotes_plus_downvotes_at_request']\n",
    "\n",
    "#text variables\n",
    "text_variables = ['giver_username_if_known',\n",
    "    'request_id',\n",
    "    'request_text',\n",
    "    'request_text_edit_aware',\n",
    "    'request_title',\n",
    "    'requester_user_flair',\n",
    "    'requester_username']\n",
    "\n",
    "#Creating empty data frames to store the training data\n",
    "numeric_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = numeric_variables)\n",
    "text_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = text_variables)\n",
    "requester_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = requester_variables)\n",
    "outcome = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = ['requester_received_pizza'])\n",
    "\n",
    "#Print the number of text and numeric predictors currently included\n",
    "print \"Number of numeric variables: \", len(numeric_elements.columns)\n",
    "print \"Number of requester variables: \", len(requester_elements.columns)\n",
    "print \"Number of text variables: \", len(text_elements.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to fill these arrays from the JSON data. Although the loop approach is less efficient at large scale, we went this direction because the number of keys varies between cases in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(jsondata2)):\n",
    "    mykeys = jsondata2[i].keys()\n",
    "    myvals = jsondata2[i].values()\n",
    "    for key, val in zip(mykeys, myvals):\n",
    "        if key in numeric_variables:\n",
    "            idx = numeric_variables.index(key)\n",
    "            numeric_elements.iloc[i, idx] = val\n",
    "        if key in requester_variables:\n",
    "            idx = requester_variables.index(key)\n",
    "            requester_elements.iloc[i, idx] = val\n",
    "        if key in text_variables:\n",
    "            idx = text_variables.index(key)\n",
    "            text_elements.iloc[i, idx] = val\n",
    "        if key == 'requester_received_pizza':\n",
    "            outcome.iloc[i,0] = val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick check on the size of these arrays - the number of columns should match the number of text and numeric predictors determined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric array:\n",
      "(4040, 22)\n",
      "\n",
      "Requester array:\n",
      "(4040, 9)\n",
      "\n",
      "Text array:\n",
      "(4040, 7)\n",
      "\n",
      "Outcome array:\n",
      "(4040, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Output shapes of numeric, text, and outcome arrays\n",
    "print \"Numeric array:\"\n",
    "print numeric_elements.shape\n",
    "print \n",
    "\n",
    "print \"Requester array:\"\n",
    "print requester_elements.shape\n",
    "print\n",
    "\n",
    "print \"Text array:\"\n",
    "print text_elements.shape\n",
    "print\n",
    "\n",
    "print \"Outcome array:\"\n",
    "print outcome.shape\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split out a dev set from the provided training data (80/20). There is no need to separate out a test set, since that is provided by Kaggle in a separate JSON file. To compare our results to other competitors in the Kaggle competition, we will need to use that test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training cases:  3232\n",
      "Number of dev cases:  808\n"
     ]
    }
   ],
   "source": [
    "random.seed(500)\n",
    "data_size = len(jsondata2)\n",
    "dev_indices = random.sample(range(data_size), data_size / 5)\n",
    "train_indices = list(set(range(data_size)) - set(dev_indices))\n",
    "\n",
    "#Define training & dev sets\n",
    "train_requester_feats = requester_elements.ix[train_indices,]\n",
    "train_outcomes = outcome.ix[train_indices,].astype(int).sum(axis = 1)\n",
    "dev_requester_feats = requester_elements.ix[dev_indices,]\n",
    "dev_outcomes = outcome.ix[dev_indices,].astype(int).sum(axis = 1)\n",
    "\n",
    "print \"Number of training cases: \", len(train_indices)\n",
    "print \"Number of dev cases: \", len(dev_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin to develop a predictive model, we must establish a baseline to give ourselves a sense of what we are trying to achieve. In our application, the following models would serve as an effective baseline: \n",
    "    1. A model that always predicts the most frequent label (in this case, no pizza).\n",
    "    2. A model that predicts outcomes with the probability of the mean response (e.g. 26.6% of requesters receive a pizza, therefore the model will predict positive outcomes 24.6% of the time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 1 Accuracy: 75.4 %\n",
      "Baseline 2 Accuracy: 63.37 %\n"
     ]
    }
   ],
   "source": [
    "y = 0\n",
    "r = 0\n",
    "outcomes = []\n",
    "for request in jsondata2:\n",
    "    if request['requester_received_pizza'] == True:\n",
    "        y+=1\n",
    "        r+=1\n",
    "        outcomes.append(1)\n",
    "    else:\n",
    "        r+=1\n",
    "        outcomes.append(0)\n",
    "avg = float(y)/float(r)\n",
    "\n",
    "#Baseline 1\n",
    "base1 = [0]*len(jsondata2)\n",
    "c = 0\n",
    "n = 0\n",
    "for i, j in zip(base1, outcomes):\n",
    "    if i == j:\n",
    "        c+=1\n",
    "        n+=1\n",
    "    else:\n",
    "        n+=1\n",
    "print 'Baseline 1 Accuracy:', round(float(c)/float(n),4)*100, '%'\n",
    "\n",
    "#Baseline 2\n",
    "base2 = np.random.binomial(1, avg, size=len(jsondata2))\n",
    "c = 0\n",
    "n = 0\n",
    "for i, j in zip(base2, outcomes):\n",
    "    if i == j:\n",
    "        c+=1\n",
    "        n+=1\n",
    "    else:\n",
    "        n+=1        \n",
    "print 'Baseline 2 Accuracy:', round(float(c)/float(n),4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Regression Model Accuracy: 75.12 % \n",
      "\n",
      "Confusion Matrix:\n",
      "[[590   7]\n",
      " [194  17]] \n",
      "\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.99      0.85       597\n",
      "          1       0.71      0.08      0.14       211\n",
      "\n",
      "avg / total       0.74      0.75      0.67       808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Simple logistic regression model\n",
    "clf = LogisticRegression(penalty = \"l2\")\n",
    "clf.fit(train_requester_feats, train_outcomes)\n",
    "preds = clf.predict(dev_requester_feats)\n",
    "probs = clf.predict_proba(dev_requester_feats)\n",
    "\n",
    "pred_probs=[]\n",
    "for prob in probs:\n",
    "    pred_probs.append(max(prob[0], prob[1]))\n",
    "\n",
    "#print pd.DataFrame(zip(preds,pred_probs))\n",
    "\n",
    "print 'Simple Regression Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, preds),4)*100, '%','\\n'\n",
    "print 'Confusion Matrix:'\n",
    "print metrics.confusion_matrix(dev_outcomes, preds), '\\n'\n",
    "print 'Classification Report:'\n",
    "print metrics.classification_report(dev_outcomes, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            features                 coefs\n",
      "5       requester_number_of_posts_on_raop_at_request      [0.416525538421]\n",
      "3    requester_number_of_comments_in_raop_at_request     [0.0854206236953]\n",
      "6          requester_number_of_subreddits_at_request    [0.00422483111215]\n",
      "1  requester_days_since_first_post_on_raop_at_req...   [0.000626867726615]\n",
      "0           requester_account_age_in_days_at_request   [0.000239981203375]\n",
      "7       requester_upvotes_minus_downvotes_at_request    [5.9236824645e-07]\n",
      "8        requester_upvotes_plus_downvotes_at_request  [-2.81743960409e-08]\n",
      "2            requester_number_of_comments_at_request  [-0.000181568291688]\n",
      "4               requester_number_of_posts_at_request  [-0.000823578378279]\n"
     ]
    }
   ],
   "source": [
    "#Examine the coefficients\n",
    "print pd.DataFrame(zip(requester_variables, np.transpose(clf.coef_)), \n",
    "                   columns=['features', 'coefs']).sort_values('coefs', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "optimal c:  1.0 ; accuracy:  75.12 %\n"
     ]
    }
   ],
   "source": [
    "#Tune hyperparameter C\n",
    "params = np.arange(0.05, 5, 0.05)\n",
    "acc = []\n",
    "\n",
    "for c in params:\n",
    "    clf = LogisticRegression(penalty = \"l2\", C=c)\n",
    "    clf.fit(train_requester_feats, train_outcomes)\n",
    "    preds = clf.predict(dev_requester_feats)\n",
    "    acc.append(metrics.accuracy_score(dev_outcomes, preds))\n",
    "\n",
    "optimal_c = params[acc.index(max(acc))]\n",
    "print 'Logistic Regression:'\n",
    "print 'optimal c: ', optimal_c, '; accuracy: ', round(max(acc), 4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that wasn't very enlightening. I'm pretty sure C defaults to 1.0...\n",
    "\n",
    "Now I'll see if it helps to normalize the features (so they are on the same scale - Z-scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Regression Model Accuracy: 74.75 %\n"
     ]
    }
   ],
   "source": [
    "#Create new dataframe to store scaled training features\n",
    "norm_train_feats = pd.DataFrame()\n",
    "\n",
    "norm_train_feats['requester_account_age_in_days_at_request'] = preprocessing.scale(train_requester_feats['requester_account_age_in_days_at_request'])\n",
    "norm_train_feats['requester_days_since_first_post_on_raop_at_request'] = preprocessing.scale(train_requester_feats['requester_days_since_first_post_on_raop_at_request'])\n",
    "norm_train_feats['requester_number_of_comments_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_comments_at_request'])\n",
    "norm_train_feats['requester_number_of_comments_in_raop_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_comments_in_raop_at_request'])                      \n",
    "norm_train_feats['requester_number_of_posts_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_posts_at_request'])    \n",
    "norm_train_feats['requester_number_of_posts_on_raop_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_posts_on_raop_at_request'])                      \n",
    "norm_train_feats['requester_number_of_subreddits_at_request'] = preprocessing.scale(train_requester_feats['requester_number_of_subreddits_at_request'])    \n",
    "norm_train_feats['requester_upvotes_minus_downvotes_at_request'] = preprocessing.scale(train_requester_feats['requester_upvotes_minus_downvotes_at_request'])\n",
    "norm_train_feats['requester_upvotes_plus_downvotes_at_request'] = preprocessing.scale(train_requester_feats['requester_upvotes_plus_downvotes_at_request'])                     \n",
    "\n",
    "#Create dataframe for scaled dev features\n",
    "norm_dev_feats = pd.DataFrame()\n",
    "\n",
    "norm_dev_feats['requester_account_age_in_days_at_request'] = preprocessing.scale(dev_requester_feats['requester_account_age_in_days_at_request'])\n",
    "norm_dev_feats['requester_days_since_first_post_on_raop_at_request'] = preprocessing.scale(dev_requester_feats['requester_days_since_first_post_on_raop_at_request'])\n",
    "norm_dev_feats['requester_number_of_comments_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_comments_at_request'])\n",
    "norm_dev_feats['requester_number_of_comments_in_raop_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_comments_in_raop_at_request'])                      \n",
    "norm_dev_feats['requester_number_of_posts_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_posts_at_request'])    \n",
    "norm_dev_feats['requester_number_of_posts_on_raop_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_posts_on_raop_at_request'])                      \n",
    "norm_dev_feats['requester_number_of_subreddits_at_request'] = preprocessing.scale(dev_requester_feats['requester_number_of_subreddits_at_request'])    \n",
    "norm_dev_feats['requester_upvotes_minus_downvotes_at_request'] = preprocessing.scale(dev_requester_feats['requester_upvotes_minus_downvotes_at_request'])\n",
    "norm_dev_feats['requester_upvotes_plus_downvotes_at_request'] = preprocessing.scale(dev_requester_feats['requester_upvotes_plus_downvotes_at_request'])                     \n",
    "\n",
    "#Create logistic regression model with normalized features\n",
    "norm_clf = LogisticRegression(penalty = \"l2\")\n",
    "norm_clf.fit(norm_train_feats, train_outcomes)\n",
    "norm_preds = norm_clf.predict(norm_dev_feats)\n",
    "\n",
    "print 'Normalized Regression Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, norm_preds),4)*100, '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the features did not yield an improvement to the model but it allows me to better visualize which features are having the greatest predictive power:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            features                coefs\n",
      "3    requester_number_of_comments_in_raop_at_request     [0.255744093693]\n",
      "5       requester_number_of_posts_on_raop_at_request     [0.173259943227]\n",
      "6          requester_number_of_subreddits_at_request     [0.064288743157]\n",
      "0           requester_account_age_in_days_at_request    [0.0563296974155]\n",
      "1  requester_days_since_first_post_on_raop_at_req...    [0.0416914310184]\n",
      "7       requester_upvotes_minus_downvotes_at_request   [0.00742909288698]\n",
      "8        requester_upvotes_plus_downvotes_at_request  [-0.00789511737875]\n",
      "2            requester_number_of_comments_at_request   [-0.0272276840178]\n",
      "4               requester_number_of_posts_at_request   [-0.0389159537653]\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(zip(requester_variables, np.transpose(norm_clf.coef_)), \n",
    "                   columns=['features', 'coefs']).sort_values('coefs', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors Model Accuracy: 73.02 %\n",
      "Nearest Neighbors (Norm. Feats) Model Accuracy: 70.67 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(algorithm='auto', n_neighbors=11) #tested 1,3,5,7,9,11,13,& 15 neighbors to select best parameter\n",
    "knn.fit(train_requester_feats, train_outcomes)\n",
    "knn_preds = knn.predict(dev_requester_feats)\n",
    "\n",
    "norm_knn = KNeighborsClassifier()\n",
    "norm_knn.fit(norm_train_feats, train_outcomes)\n",
    "norm_knn_preds = norm_knn.predict(norm_dev_feats)\n",
    "\n",
    "print 'Nearest Neighbors Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, knn_preds),4)*100, '%'\n",
    "print 'Nearest Neighbors (Norm. Feats) Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, norm_knn_preds),4)*100, '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Centroid\n",
    "\n",
    "The Nearest Centroid classifier is a simple algorithm that represents each class by the centroid of its members. A new set of features is classified based on its distance from the centroids of the features in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Centroid Model Accuracy: 67.7 %\n",
      "Nearest Centroid (Norm. Feats) Model Accuracy: 65.84 %\n"
     ]
    }
   ],
   "source": [
    "nc = NearestCentroid()\n",
    "nc.fit(train_requester_feats, train_outcomes)\n",
    "nc_preds = nc.predict(dev_requester_feats)\n",
    "\n",
    "norm_nc = NearestCentroid()\n",
    "norm_nc.fit(norm_train_feats, train_outcomes)\n",
    "norm_nc_preds = norm_nc.predict(norm_dev_feats)\n",
    "\n",
    "print 'Nearest Centroid Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, nc_preds),4)*100, '%'\n",
    "print 'Nearest Centroid (Norm. Feats) Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, norm_nc_preds),4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests Model Accuracy ( 26 estimators ): 73.64 %\n"
     ]
    }
   ],
   "source": [
    "estimators=[]\n",
    "accuracies=[]\n",
    "\n",
    "for i in range(1,30):\n",
    "    rf = RandomForestClassifier(n_estimators=i, random_state=99)\n",
    "    rf.fit(train_requester_feats, train_outcomes)\n",
    "    rf_preds=rf.predict(dev_requester_feats)\n",
    "    acc = metrics.accuracy_score(dev_outcomes, rf_preds)\n",
    "    estimators.append(i)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "max_acc = max(accuracies)\n",
    "est = estimators[accuracies.index(max_acc)]\n",
    "print 'Random Forests Model Accuracy (', est, 'estimators ):', round(max_acc,4)*100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Learner\n",
    "Lastly, I will test a model that takes the most frequent prediction from the logistic regression, nearest neighbors (n=11), & random forest (n_estimators=26) models outlined above as its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ensemble Learner Model Accuracy: 72.77 %\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "reg = LogisticRegression(penalty=\"l2\", C=1.0)\n",
    "reg.fit(train_requester_feats, train_outcomes)\n",
    "reg_preds = clf.predict(dev_requester_feats)\n",
    "\n",
    "#Nearest Neighbors\n",
    "knn = KNeighborsClassifier(algorithm='auto', n_neighbors=11)\n",
    "knn.fit(train_requester_feats, train_outcomes)\n",
    "knn_preds = knn.predict(dev_requester_feats)\n",
    "\n",
    "#Random Forests\n",
    "rf = RandomForestClassifier(n_estimators=26, random_state=99)\n",
    "rf.fit(train_requester_feats, train_outcomes)\n",
    "rf_preds=rf.predict(dev_requester_feats)\n",
    "\n",
    "ensemble_preds=[]\n",
    "\n",
    "for i,j,k in zip(reg_preds, knn_preds, rf_preds):\n",
    "    pred=[]\n",
    "    pred.append(i), pred.append(j), pred.append(k)\n",
    "    ensemble_preds.append(max(set(pred)))\n",
    "    \n",
    "print 'Ensemble Learner Model Accuracy:', round(metrics.accuracy_score(dev_outcomes, ensemble_preds),4)*100, '%'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, here are the models, ranked in terms of accuracy, for requester features: \n",
    "  \n",
    "1) Logistic regression (non-normalized feats) - 75.12%  \n",
    "2) Random forests - 73.64%  \n",
    "3) Nearest neighbors - 73.02%  \n",
    "4) Ensemble learner - 72.77%  \n",
    "5) Nearest centroid - 67.7%  \n",
    "  \n",
    "All 5 models were better than guessing based on the outcome distribution (63.37%) but were not better than guessing the most common outcome (75.4%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
