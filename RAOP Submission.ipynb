{
 "metadata": {
  "name": "",
  "signature": "sha256:333906c1f31339f8cb850082ce27ab89b9d975e782886615e8767136a03a6783"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Random Acts of Pizza Project"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Team Members: Divyang Prateek, Brennan Borlaug, Cory Kind"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data Import and Setup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start by importing relevant libraries for storing and analyzing data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json as js\n",
      "import random\n",
      "import os\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import metrics\n",
      "import datetime\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.feature_extraction.text import *\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn import preprocessing\n",
      "from sklearn.decomposition import PCA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read in JSON file of training data, provided by Kaggle."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir(\"/Users/Cory/Dropbox/Berkeley/(W207) Applied Machine Learning/Random Acts of Pizza\")\n",
      "#Reads the json file as a String\n",
      "data2 = open(\"train.json\").read()\n",
      "#Converts JSON string to a List of Dictionaries\n",
      "jsondata2 = js.loads(data2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The RAOP data contains a variety of predictors of different formats. This step puts variables into separate categories for text and numeric, and creates an array for the outcome we are trying to predict (\"requester_received_pizza\"). We decided it was easier to work with text and numeric variables separately at this stage."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#numeric variables\n",
      "numeric_variables = ['number_of_downvotes_of_request_at_retrieval',\n",
      "    'number_of_upvotes_of_request_at_retrieval',\n",
      "    'post_was_edited',\n",
      "    'request_number_of_comments_at_retrieval',\n",
      "    'requester_account_age_in_days_at_request',\n",
      "    'requester_account_age_in_days_at_request',\n",
      "    'requester_account_age_in_days_at_retrieval',\n",
      "    'requester_days_since_first_post_on_raop_at_request',\n",
      "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
      "    'requester_number_of_comments_at_request',\n",
      "    'requester_number_of_comments_at_retrieval',\n",
      "    'requester_number_of_comments_in_raop_at_request',\n",
      "    'requester_number_of_comments_in_raop_at_retrieval',\n",
      "    'requester_number_of_posts_at_request',\n",
      "    'requester_number_of_posts_at_retrieval',\n",
      "    'requester_number_of_posts_on_raop_at_request',\n",
      "    'requester_number_of_posts_on_raop_at_retrieval',\n",
      "    'requester_number_of_subreddits_at_request',\n",
      "    'requester_upvotes_minus_downvotes_at_request',\n",
      "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
      "    'requester_upvotes_plus_downvotes_at_request',\n",
      "    'requester_upvotes_plus_downvotes_at_retrieval',\n",
      "    'unix_timestamp_of_request_utc']\n",
      "\n",
      "#requester variables (from time of request)\n",
      "requester_variables = ['requester_account_age_in_days_at_request',\n",
      "                      'requester_days_since_first_post_on_raop_at_request',\n",
      "                      'requester_number_of_comments_at_request',\n",
      "                      'requester_number_of_comments_in_raop_at_request',\n",
      "                      'requester_number_of_posts_at_request',\n",
      "                      'requester_number_of_posts_on_raop_at_request',\n",
      "                      'requester_number_of_subreddits_at_request',\n",
      "                      'requester_upvotes_minus_downvotes_at_request',\n",
      "                      'requester_upvotes_plus_downvotes_at_request']\n",
      "\n",
      "\n",
      "#text variables\n",
      "text_variables = ['giver_username_if_known',\n",
      "    'request_id',\n",
      "    'request_text',\n",
      "    'request_text_edit_aware',\n",
      "    'request_title',\n",
      "    'requester_user_flair',\n",
      "    'requester_username']\n",
      "\n",
      "#Creating empty data frames to store the training data\n",
      "numeric_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = numeric_variables)\n",
      "text_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = text_variables)\n",
      "requester_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = requester_variables)\n",
      "outcome = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = ['requester_received_pizza'])\n",
      "\n",
      "#Print the number of text and numeric predictors currently included\n",
      "print \"Number of numeric variables: \", len(numeric_elements.columns)\n",
      "print \"Number of text variables: \", len(text_elements.columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of numeric variables:  23\n",
        "Number of text variables:  7\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next step is to fill these arrays from the JSON data. Although the loop approach is less efficient at large scale, we went this direction because the number of keys varies between cases in the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(jsondata2)):\n",
      "    mykeys = jsondata2[i].keys()\n",
      "    myvals = jsondata2[i].values()\n",
      "    for key, val in zip(mykeys, myvals):\n",
      "        if key in numeric_variables:\n",
      "            idx = numeric_variables.index(key)\n",
      "            numeric_elements.iloc[i, idx] = val\n",
      "        if key in requester_variables:\n",
      "            idx = requester_variables.index(key)\n",
      "            requester_elements.iloc[i, idx] = val\n",
      "        if key in text_variables:\n",
      "            idx = text_variables.index(key)\n",
      "            text_elements.iloc[i, idx] = val\n",
      "        if key == 'requester_received_pizza':\n",
      "            outcome.iloc[i,0] = val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a quick check on the size of these arrays - the number of columns should match the number of text and numeric predictors determined above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Output shapes of numeric, text, and outcome arrays\n",
      "print \"Numeric array:\"\n",
      "print numeric_elements.shape\n",
      "print \n",
      "\n",
      "print \"Requester array:\"\n",
      "print requester_elements.shape\n",
      "print\n",
      "\n",
      "print \"Text array:\"\n",
      "print text_elements.shape\n",
      "print\n",
      "\n",
      "print \"Outcome array:\"\n",
      "print outcome.shape\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Numeric array:\n",
        "(4040, 23)\n",
        "\n",
        "Requester array:\n",
        "(4040, 9)\n",
        "\n",
        "Text array:\n",
        "(4040, 7)\n",
        "\n",
        "Outcome array:\n",
        "(4040, 1)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we split out a dev set from the provided training data (80/20). There is no need to separate out a test set, since that is provided by Kaggle in a separate JSON file. To compare our results to other competitors in the Kaggle competition, we will need to use that test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.seed(500)\n",
      "data_size = len(jsondata2)\n",
      "dev_indices = random.sample(range(data_size), data_size / 5)\n",
      "train_indices = list(set(range(data_size)) - set(dev_indices))\n",
      "\n",
      "#Define training & dev sets\n",
      "train_requester_feats = requester_elements.ix[train_indices,]\n",
      "train_outcomes = outcome.ix[train_indices,].astype(int).sum(axis = 1)\n",
      "dev_requester_feats = requester_elements.ix[dev_indices,]\n",
      "dev_outcomes = outcome.ix[dev_indices,].astype(int).sum(axis = 1)\n",
      "\n",
      "print \"Number of training cases: \", len(train_indices)\n",
      "print \"Number of dev cases: \", len(dev_indices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of training cases:  3232\n",
        "Number of dev cases:  808\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Establishing Our Baseline(s)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Feature Extraction"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Fitting Models"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model Optimization"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Final Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}