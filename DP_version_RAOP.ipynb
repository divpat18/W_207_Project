{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Acts of Pizza Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divyang Prateek and Cory Kind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing and structuring data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing relevant libraries for storing and analyzing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json as js\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in JSON file of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reads the json file as a String\n",
    "data2 = open(\"train.json\").read()\n",
    "#Converts JSON string to a List of Dictionaries\n",
    "jsondata2 = js.loads(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RAOP data contains a variety of predictors of different formats. This step puts variables into separate categories for text and numeric, and creates an array for the outcome we are trying to predict (\"requester_received_pizza\"). We decided it was easier to work with text and numeric variables separately at this stage.\n",
    "\n",
    "\n",
    "NOTE that the following variables are not currently imported because they require extra processing. They will be addressed at a later point, but are not required for the baseline.\n",
    "\n",
    "1) requester_subreddits_at_request (returns an array)\n",
    "\n",
    "2) unix timestamp of request (date format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric variables:  23\n",
      "Number of text variables:  7\n"
     ]
    }
   ],
   "source": [
    "#numeric variables\n",
    "numeric_variables = ['number_of_downvotes_of_request_at_retrieval',\n",
    "    'number_of_upvotes_of_request_at_retrieval',\n",
    "    'post_was_edited',\n",
    "    'request_number_of_comments_at_retrieval',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_account_age_in_days_at_request',\n",
    "    'requester_account_age_in_days_at_retrieval',\n",
    "    'requester_days_since_first_post_on_raop_at_request',\n",
    "    'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "    'requester_number_of_comments_at_request',\n",
    "    'requester_number_of_comments_at_retrieval',\n",
    "    'requester_number_of_comments_in_raop_at_request',\n",
    "    'requester_number_of_comments_in_raop_at_retrieval',\n",
    "    'requester_number_of_posts_at_request',\n",
    "    'requester_number_of_posts_at_retrieval',\n",
    "    'requester_number_of_posts_on_raop_at_request',\n",
    "    'requester_number_of_posts_on_raop_at_retrieval',\n",
    "    'requester_number_of_subreddits_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_request',\n",
    "    'requester_upvotes_minus_downvotes_at_retrieval',\n",
    "    'requester_upvotes_plus_downvotes_at_request',\n",
    "    'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "    'unix_timestamp_of_request_utc']\n",
    "\n",
    "#text variables\n",
    "text_variables = ['giver_username_if_known',\n",
    "    'request_id',\n",
    "    'request_text',\n",
    "    'request_text_edit_aware',\n",
    "    'request_title',\n",
    "    'requester_user_flair',\n",
    "    'requester_username']\n",
    "\n",
    "#Creating empty data frames to store the training data\n",
    "numeric_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = numeric_variables)\n",
    "text_elements = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = text_variables)\n",
    "outcome = pd.DataFrame(np.nan, index = range(len(jsondata2)), columns = ['requester_received_pizza'])\n",
    "\n",
    "#Print the number of text and numeric predictors currently included\n",
    "print \"Number of numeric variables: \", len(numeric_elements.columns)\n",
    "print \"Number of text variables: \", len(text_elements.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to fill these arrays from the JSON data. Although the loop approach is less efficient at large scale, we went this direction because the number of keys varies between cases in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(jsondata2)):\n",
    "    mykeys = jsondata2[i].keys()\n",
    "    myvals = jsondata2[i].values()\n",
    "    for key, val in zip(mykeys, myvals):\n",
    "        if key in numeric_variables:\n",
    "            idx = numeric_variables.index(key)\n",
    "            numeric_elements.iloc[i, idx] = val\n",
    "        if key in text_variables:\n",
    "            idx = text_variables.index(key)\n",
    "            text_elements.iloc[i, idx] = val\n",
    "        if key == 'requester_received_pizza':\n",
    "            outcome.iloc[i,0] = val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a quick check on the size of these arrays - the number of columns should match the number of text and numeric predictors determined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric array:\n",
      "(4040, 23)\n",
      "\n",
      "Text array:\n",
      "(4040, 7)\n",
      "\n",
      "Outcome array:\n",
      "(4040, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Output shapes of numeric, text, and outcome arrays\n",
    "print \"Numeric array:\"\n",
    "print numeric_elements.shape\n",
    "print \n",
    "\n",
    "print \"Text array:\"\n",
    "print text_elements.shape\n",
    "print\n",
    "\n",
    "print \"Outcome array:\"\n",
    "print outcome.shape\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we split out a dev set from the provided training data (80/20). There is no need to separate out a test set, since that is provided by Kaggle in a separate JSON file. To compare our results to other competitors in the Kaggle competition, we will need to use that test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training cases:  3232\n",
      "Number of dev cases:  808\n"
     ]
    }
   ],
   "source": [
    "random.seed(500)\n",
    "data_size = len(jsondata2)\n",
    "dev_indices = random.sample(range(data_size), data_size / 5)\n",
    "train_indices = list(set(range(data_size)) - set(dev_indices))\n",
    "\n",
    "print \"Number of training cases: \", len(train_indices)\n",
    "print \"Number of dev cases: \", len(dev_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pull out the request text and outcomes for training and dev sets\n",
    "train_request_text = text_elements.ix[train_indices, \"request_text\"]\n",
    "dev_request_text = text_elements.ix[dev_indices, \"request_text\"]\n",
    "\n",
    "train_outcome = outcome.ix[train_indices,].astype(int).sum(axis = 1)\n",
    "dev_outcome = outcome.ix[dev_indices,].astype(int).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extracting the numerical data and converting to datetime.\n",
    "train_request_time = numeric_elements.ix[train_indices,\"unix_timestamp_of_request_utc\"].astype(long)\n",
    "train_request_dateTime = [datetime.datetime.fromtimestamp(time) for time in train_request_time]\n",
    "dev_request_time = numeric_elements.ix[dev_indices,\"unix_timestamp_of_request_utc\"].astype(long)\n",
    "dev_request_dateTime = [datetime.datetime.fromtimestamp(time) for time in dev_request_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score : 0.706683168317\n",
      "Logistic Regression Score : 0.738861386139\n"
     ]
    }
   ],
   "source": [
    "train_month = np.asarray([time.month for time in train_request_dateTime]).reshape((len(train_request_time),1))\n",
    "train_month_label = np.asarray(train_outcome)\n",
    "\n",
    "dev_month = np.asarray([time.month for time in dev_request_dateTime]).reshape((len(dev_request_time),1))\n",
    "dev_month_label = np.asarray(dev_outcome)\n",
    "\n",
    "knn_clf  = KNeighborsClassifier()\n",
    "knn_clf = knn_clf.fit(train_month,train_month_label)\n",
    "print 'KNN Score :',knn_clf.score(dev_month,dev_month_label)\n",
    "\n",
    "lr_clf = LogisticRegression(C=1)\n",
    "lr_clf = lr_clf.fit(train_month,train_month_label)\n",
    "print 'Logistic Regression Score :',lr_clf.score(dev_month,dev_month_label)\n",
    "\n",
    "rf_clf = Ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score : 0.738861386139\n",
      "Logistic Regression Score : 0.738861386139\n"
     ]
    }
   ],
   "source": [
    "train_holiday_season = np.asarray([time.month >= 10 for time in train_request_dateTime]).reshape((len(train_request_time),1))\n",
    "train_holiday_label = np.asarray(train_outcome)\n",
    "\n",
    "dev_holiday_season = np.asarray([time.month >= 10 for time in dev_request_dateTime]).reshape((len(dev_request_time),1))\n",
    "dev_holiday_label = np.asarray(dev_outcome)\n",
    "\n",
    "knn_clf  = KNeighborsClassifier()\n",
    "knn_clf = knn_clf.fit(train_holiday_season,train_holiday_label)\n",
    "print 'KNN Score :',knn_clf.score(dev_holiday_season,dev_holiday_label)\n",
    "\n",
    "lr_clf = LogisticRegression(C=1)\n",
    "lr_clf = lr_clf.fit(train_holiday_season,train_holiday_label)\n",
    "print 'Logistic Regression Score :',lr_clf.score(dev_holiday_season,dev_holiday_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Score : 0.738861386139\n",
      "Logistic Regression Score : 0.738861386139\n"
     ]
    }
   ],
   "source": [
    "train_payday_effect = np.asarray([(time.day > 26 or time.day<2) for time in train_request_dateTime]).reshape((len(train_request_time),1))\n",
    "train_payday_label = np.asarray(train_outcome)\n",
    "\n",
    "dev_payday_effect = np.asarray([(time.day > 26 or time.day<2) for time in dev_request_dateTime]).reshape((len(dev_request_time),1))\n",
    "dev_payday_label = np.asarray(dev_outcome)\n",
    "\n",
    "knn_clf_pe  = KNeighborsClassifier()\n",
    "knn_clf_pe = knn_clf_pe.fit(train_payday_effect,train_payday_label)\n",
    "print 'KNN Score :',knn_clf.score(dev_payday_effect,dev_payday_label)\n",
    "\n",
    "lr_clf = LogisticRegression(C=1)\n",
    "lr_clf = lr_clf.fit(train_payday_effect,train_payday_label)\n",
    "print 'Logistic Regression Score :',lr_clf.score(dev_payday_effect,dev_payday_label)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
